import pandas as pd
import os
import glob

# parse samples metadata
samples_tbl=config["samples"]
samples_meta=pd.read_csv(samples_tbl, header = None, dtype = str)
samples_meta.columns=["Sample", "Path"]
samples_meta=samples_meta.set_index("Sample", drop = False)

# get list of segments to generate
segments = str(config['segments']).replace('(', '').replace(')','').split(',')
segment_l = ["segment_" + s for s in segments]

# load rules
include: "rules/common.smk"
include: "rules/read_summary.smk"

# override current working directory
workdir: config["outdir"]

# define pipeline target
rule all:
  input: 
      expand("{sample}/consensus/{segment}.fa", sample=samples_meta.Sample, segment=segment_l),
      "InfA_analysis_viz.html"

#rule all:
#  input: expand("{sample}/subsample_fastq/{segment}.fastq", sample=samples_meta.Sample, segment=segment_l)

#rule all:
#  input:
#    "InfA_analysis_viz.html"

rule combine_fastq:
  input:
    fastq_dir=lambda wildcards: samples_meta.Path[wildcards.sample]
  output:
    combined_fastq="{sample}/{sample}.fastq"
  threads: 1
  shell:
    "cat {input.fastq_dir}/*.fastq > {output.combined_fastq}"

rule combine_fastq_gz:
  input:
    fastq_dir=lambda wildcards: samples_meta.Path[wildcards.sample]
  output:
    combined_fastq="{sample}/{sample}.fastq.gz"
  threads: 1
  shell:
    """
    cat {input.fastq_dir}/*.fastq.gz > {output.combined_fastq}
    """

rule porechop:
  input:
    reads=combined_output
  threads: 32
  output:
    trimmed_reads="{sample}/porechop/{sample}_trimmed.fastq"
  shell:
    """
    porechop -t {threads} -i {input.reads} -o {output.trimmed_reads}
    """

rule centrifuge:
  input:
    reads=centrifuge_input
  threads: 32
  params:
    db=config["centrifuge_db"]
  output:
    centrifuge_res="{sample}/centrifuge/centrifuge_res.tsv",
    centrifuge_report="{sample}/centrifuge/centrifuge_report.tsv"
  shell:
    """
    centrifuge -p {threads} -U {input.reads} -x {params.db} -S {output.centrifuge_res} \
      --report-file {output.centrifuge_report} -k 50 --ignore-quals
    """

rule partition:
  input:
    centrifuge_res="{sample}/centrifuge/centrifuge_res.tsv",
    reads=centrifuge_input
  threads: 4
  params:
    segment="{segment}",
    ID_mappings=config["pipeline_dir"]+"/database/InfA_refseq_segment_mappings.csv",
    pipeline_dir=config["pipeline_dir"],
    mode=config['mode']
  output:
    segment_readIDs="{sample}/centrifuge/{segment}_reads.ids",
    InfA_reads="{sample}/fastq/{segment}.fastq",
    binned_readIDs="{sample}/binned_fastq/{segment}.reads.ids",
    binned_reads="{sample}/binned_fastq/{segment}.fastq",
    binned_read_lengths="{sample}/binned_fastq/{segment}.read.lengths"
  shell:
    """
    Rscript {params.pipeline_dir}/src/centrifuge_res_process.R {input.centrifuge_res} \
      {params.ID_mappings} \
      {params.segment} \
      {output.binned_readIDs} \
      {output.segment_readIDs} \
      {output.binned_read_lengths} \
      {params.mode}
    
    seqtk subseq {input.reads} {output.segment_readIDs} > {output.InfA_reads}
    seqtk subseq {input.reads} {output.binned_readIDs} > {output.binned_reads}
    """

rule subsample:
  input: "{sample}/fastq/{segment}.fastq"
  output: 
    subsample="{sample}/subsample_fastq/{segment}.fastq"
  params: config["subsample"]
  threads: 4
  shell:
    """
    if (( $(echo $(cat {input} | wc -l) / 4 | bc) > 1000 )); then
      seqtk sample -s100 {input} {params} > {output.subsample}
    else
      cp {input} {output.subsample}
    fi
    """

rule draft_consensus:
  input: "{sample}/subsample_fastq/{segment}.fastq"
  output: "{sample}/draft_consensus/{segment}.fasta"
  params: 
    segment="{segment}",
    segment_name=lambda wildcards: get_segment_name(wildcards.segment),
    sample_name="{sample}"
  threads: 4
  shell:
    """
    if [ -s {input} ]; then
    spoa -l 1 -s {input} > {output}
    sed -i "s/>/>{params.segment_name}\/{params.sample_name} /g" {output}
    else
    echo "influenza_consensus: Failed to detect any full-length reads for Segment $(echo {params.segment} {params.segment_name} | sed 's/segment_//g'), exiting"
    exit 1    
    fi
    """

rule medaka:
  input:
    InfA_reads="{sample}/subsample_fastq/{segment}.fastq",
    draft_consensus="{sample}/draft_consensus/{segment}.fasta"
  threads: config["threads"]
  params:
    outdir="{sample}/medaka/{segment}",
    model=config["model"]
  output:
    consensus="{sample}/consensus/{segment}.fa"
  shell:
    """
    medaka_consensus -i {input.InfA_reads} -d {input.draft_consensus} -o {params.outdir} -t {threads} -m {params.model} -f
    cp {params.outdir}/consensus.fasta {output.consensus}
    """  